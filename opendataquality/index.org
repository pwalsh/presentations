#+OPTIONS: toc:nil
#+OPTIONS: num:nil
#+REVEAL_THEME:black
#+REVEAL_EXTRA_CSS: ./assets/extra.css

* Open Data and the Question of Quality

#+REVEAL_HTML: <i class="fa fa-archive" aria-hidden="true"></i>

#+BEGIN_NOTES

Published title:

"What's next in open data? The limits of the publication discourse"

Blurb:

In 2017, discourse around open data still revolves around publication of open data. While clearly important, it is like talking about building roads without thought towards their ability to facilitate transport. We need a radical shift in discourse towards data quality in order to facilitate the ability to use open data.

The talk will cover a little history to show the historical forces that got us to where we are today - lots of open data portals full of barely reusable data, and present a vision for where we need to be and how we could get there, in order for open data to truly fulfil its promise as a channel of empowerment.

#+END_NOTES

* Open Knowledge International

#+ATTR_HTML: :width 200px
#+ATTR_ORG: :width 200
[[./assets/oki.png]]

** 

Open up all essential, public interest information and see it used to create insight that drives positive change.

#+BEGIN_NOTES

1. Why I am talking about open data quality
2. What my role is in open data and with OKI (Product: tech / specs)
3. What OKI's role is in open data (Open Definition, CKAN, others)

------

If we are going to talk about open data and the question of quality, Let's first briefly discuss why the quality of open data is important to me.

- I'm the *Chief Product Officer* at Open Knowledge International [ https://okfn.org ]

- Open Knowledge International, founded by Rufus Pollock in 2004, has a history deeply intwined with open data as we understand it today.

- We've both led, and been deeply involved in, a number of key efforts around the open data space:

  - *Open Definition* [ http://opendefinition.org ]: The Open Definition sets out principles that define “openness” in relation to data and content.

  - *CKAN* [ https://ckan.org ]: The first and leading open data portal, used by governments and other publishing bodies around the world.

  - *Global Open Data Index* [ http://index.okfn.org ]: Measuring the openness of goverments by way of their open data publication.

  - A range of other open source apps, libraries and platforms for open data, like:
    - *Frictionless Data* [ https://frictionlessdata.io ]
    - *OpenSpending* [ https://openspending.org ]
    - *OpenTrials* [ https://explorer.opentrials.net ]

- We love open data, and most importantly, want to see it drive change in the world. This is important to the context of the talk around publication and quality.

- Me, I'm a hacker with a background in anthropology

#+END_NOTES

* This talk

#+REVEAL_HTML: <i class="fa fa-road" aria-hidden="true"></i>

** 

- The open data ecosystem is almost exclusively about publication
- This focus on publication is now minimising the impact of open data
- To meet the promise of open data, we need to focus on data quality

#+BEGIN_NOTES

1. Summary of the talk flow
2. Listeners can get context / what to expect

------

Here I want to paint in broad strokes what I essentially want to say over the next 20 minutes.

- *show* the focus on publication?

- *how* does it minimise impact?

- *why* do we need to shift the focus to data quality?

We are going to now look at this in more detail.

Looked at like this, it may seem obvious or evident, but we'll see in fact that what is happening with open data right now is far from this.

#+END_NOTES

** 

- Some ideas to think about technology of "what's next" (because most of us here are technologists)
- Some concrete actions you can take in front of your local public bodies that publish open data

#+BEGIN_NOTES

1. The talk is oriented towards action.
2. Tech action, in terms of tools to build and the goal we are aiming for.
3. Non-tech action in terms of pressuring publishing bodies.

------

If I've done my job well enough, this is what you should come out of the talk with - not only listening to some person's opinion about open data, but a set of actions.

#+END_NOTES

* Definitions

#+REVEAL_HTML: <i class="fa fa-map-signs" aria-hidden="true"></i>

** 

#+BEGIN_QUOTE
Open data is digital data that is made available with the technical and legal characteristics necessary for it to be freely used, reused, and redistributed by anyone, anytime, anywhere.
[[http://opendatacharter.net/principles/][Open Data Charter]]
#+END_QUOTE

#+BEGIN_NOTES

1. We have a clear definition of what open data is.
2. The definition I am using is from the Open Data Charter. It is in turn based on earlier work from OKI and others on the Open Definition.
3. While the definition applies to data in general, it is still mostly used in the context of government data. This is changing (Open Trials example), but the examples in this talk are also related to government data.

------

Before we talk about the state of open data, and open data quality, we need to define what we mean by open data.

*Open Definition* http://opendefinition.org

"Open data and content can be freely used, modified, and shared by anyone for any purpose"

"The Open Definition makes precise the meaning of “open” with respect to knowledge, promoting a robust commons in which anyone may participate, and interoperability is maximized."

#+END_NOTES

* Is it important?

#+REVEAL_HTML: <i class="fa fa-snowflake-o" aria-hidden="true"></i>

** 

- It's our data
- A type of accountability
- New types of participatory cultures
- Insight -> change in the world

#+BEGIN_NOTES

1. Let's stop here for a second and ask: Why is Open Data important?
2. Our governments should be accountable to us. Publishing data on what they do is an important form of accountability.
3. Open data, on top of infrastructure like the Internet, feeds new participatory cultures. Activists, NGOs, businesses, etc.

------

From the Open Data Charter http://opendatacharter.net/principles/ :

"Open data enables governments, citizens, and civil society and private sector organizations to make better informed decisions"

"We, the adherents to the International Open Data Charter, recognize that governments and other public sector organizations hold vast amounts of data that may be of interest to citizens, and that this data is an underused resource. Opening up government data can encourage the building of more interconnected societies that better meet the needs of our citizens and allow innovation, justice, transparency, and prosperity to flourish, all while ensuring civic participation in public decisions and accountability for governments."

"Open data allows user to compare, combine, and follow the connections among different datasets, tracing data across a number of programs and sectors. When data can be effectively combined and compared, it can help highlight trends, identify social and economic challenges and inequities, and benchmark progress in public programs and services."


So, one thing is clear: it is important, but not in and of itself. Open data is a means to an end. open data is important in correspondenence with the change it can affect in the world.

#+END_NOTES

* Where are we now?

#+REVEAL_HTML: <i class="fa fa-globe" aria-hidden="true"></i>

#+BEGIN_NOTES

1. Open data movement is an established ecosystem or "industry".
2. Governments are eager to tie open data into their transparency efforts.
3. While this growth is a net positive, there are troubling issues with open data quality that are not being addressed at the government level (still pre-ccupied with publication, and the ecosystem incentivises this).

------

It's 2017 and we are 10 years in to open data. Over that time, an entire movement has established itself with reference to government data specifically, but also a more general idea of open data. Of course, refering to this time from does not mean all data was "closed" before this period.

However, the digital economy afforded by the World Wide Web and other technological advancements truly gave rise to an entity and concept in its own right, one that is now represented via a range of CSOs, coalitions like the Open Government Partnership, and initiatives like the Open Data Charter.

Is open data as a concept and a force healthy? Is the promise of open data being fulfilled? Can we see clearly where open data needs to go?

#+END_NOTES

** Field

- Freedom of Information (FOI)
- Publication and the open data portal
- Transparency initiatives and open data
- Meta-national partnerships and alliances

#+BEGIN_NOTES

1. Freedom of information acts in many juristrictions are a critical tool for actors to get data from governments. Implements the notion of the citizen right to data.
2. Many governments proactively publish data via portals. Portals are therefore a major interface for civil society to access open data. (history with data.gov.uk and data.gov)
3. Open data has been closely tied to the notion of government transparency. Data often functions as a signifier of transparency.
4. The "industry" engaging with government via generic action, as opposed to earlier more localised/specific actions.

------

https://en.wikipedia.org/wiki/Freedom_of_information_laws_by_country

#+END_NOTES

** Actors

- NGOs
- Civic tech
- Governments
- Philanthropists

#+BEGIN_NOTES

Open Knowledge International, Open Data Institute, Sunlight Foundation, Transparency International

#+END_NOTES

** Metrics / Incentives

[[./assets/godi.png]]

#+BEGIN_NOTES

http://index.okfn.org

1. Crowdsourced "assessment by the people, for the people".
2. *Lots* of government interest. Directly influences transparency policies.
3. Focussed on publication and access. (good things!)

#+END_NOTES

** Metrics / Incentives

[[./assets/bar.png]]

#+BEGIN_NOTES

http://opendatabarometer.org

1. Government self assessment.
2. Peer-reviewed expert survey.
3. Secondary data from other sources (e.g.: World Bank).

#+END_NOTES

** Metrics / Incentives

[[./assets/ogp.png]]

#+BEGIN_NOTES

https://www.opengovpartnership.org

1. Eligibility based on access to, and timely publication of, some types of data (fiscal, asset disclosure).
2. National Action Plan in conjunction with civil society.
3. Self-assessment and the Independent Report Mechanism.

#+END_NOTES

** Metrics / Incentives

[[./assets/odc.png]]

#+BEGIN_NOTES

http://opendatacharter.net

1. A set of principles for access, release and use of data.
2. Adoption via a high-level public statement.

#+END_NOTES

* What we don't see

#+REVEAL_HTML: <i class="fa fa-eye-slash" aria-hidden="true"></i>

** 

- We don't measure the usability of open data
- We don't expect open data to be of high quality
- We don't incentivise government to strive for impact (reuse, insight, change)

#+BEGIN_NOTES

1. There is little emphasis by the actors in the field of open data on usability. The discourse around publication actually deemphaises usability.
2. Civic tech barely expects open data to be of high quality. Data wrangling to simply use public data is normal.
3. No one asks governments to measure their success via action on the world.

#+END_NOTES

* Studies

#+REVEAL_HTML: <i class="fa fa-book" aria-hidden="true"></i>

** 

- Who are the users of open data?
- What are their user experiences?
- What can we learn about data quality?

#+BEGIN_NOTES

Civic tech and open data organisations are the primary users of open data

#+END_NOTES

** UK spend data

[[./assets/uk-25k.png]]

#+BEGIN_NOTES

1. Position of UK in open data and transparency.
2. Particularly clear requirements and a willing, capable and funded team internally.
3. A mixture of automated and manually generated data. Decentralised data collection and publication.

------

In late 2014, I worked on a project at OKI in collaboration with [[https://www.gov.uk/government/organisations/cabinet-office/about][Cabinet Office]] around measuring the UK government's transparency efforts around spending. Many of the core tools that are now part of the Frictionless Data toolchain came out of this work.

A primary goal was to look at spend publishing, particularly data we referred to as the UK "25k" data, check the quality of the data published, and build a dashboard for internal stakeholders to see and measure their own fiscal transparency and data publication status.

The "25k" data is interesting for a number of reasons.

For one, the data covers a wide range of administrative departments across central government, detailing their spending on any items with a value of over £25,000.

More interestingly, the publication of this data was a top-down initiative, stemming from an order by the Prime Minister in May 2010 that each department will have a minister responsible for transparency, and that this was tied directly to accountaibility and driving down costs.

As part of this initiative, the government made a commitment to publish details of all expenditure over £25,000, and the giveronment released fairly detailed and clear guidance for how this data was to be published. Read more on this [[https://www.gov.uk/government/uploads/system/uploads/attachment_data/file/198197/Guidance_for_publishing_spend_over__25k.pdf][here]].

Here we have an example of:

- A requirement to publish open data
- A need driven by transparency and accountability narratives
- Clear, simple information for all departments on how to prepare and release this data
- Data that has a "standard" -  a very explicit description of the fields and type of data to be released (see an extraction of this standard from the above linked document [[https://gist.github.com/pwalsh/a9f7f0796229d0566191][here]]).

So, just how good is the data?

Our scripts for collecting and processing the data, as well as copies of the data, can be found on [[https://github.com/okfn/data-quality-uk-25k-spend][Github]]. [[https://github.com/okfn/data-quality-uk-25k-spend/blob/master/README.md][The README.md]] file contains a detailed description of what we did, how we defined "data quality" in this context, and explains to process by which we acquired the data.


Note that the quality problems start with the discoverability of the data itself. There is no way via any UK government portal to simply collect all this data via an existing taxonomy. We had to write custom code on top of the CKAN search API (data.gov.uk runs on CKAN) to try to find all UK25k data. Logic for this can be found in [[https://github.com/okfn/data-quality-uk-25k-spend/blob/master/scripts/id_data.py#L292][this function]] and other functions in [[https://github.com/okfn/data-quality-uk-25k-spend/blob/master/scripts/id_data.py][this module]].

However, our story, today, is not about the discoverability of the data as such, but the quality of the data itself.

To get to the point, we have a display of the latest results available on an instance of our [[http://uk-25k.herokuapp.com][Data Quality Dashboard for this data]]. By the scoring system we used, less than 1% (rounded to 0) of the data meets the UK governments own quality standards for this data.

Here is an [[http://goodtables.okfnlabs.org/reports?data_url=https://www.gov.uk/government/uploads/system/uploads/attachment_data/file/532146/dwp-payments-over-25000-for-may-2016.csv&format=csv&encoding=&schema_url=https://raw.githubusercontent.com/okfn/goodtables/master/examples/hmt/spend-publishing-schema.json][example of the errors found]], in a file for May 2016 from the Depaertment of Work and Pensions. You can find similar errors elsewhere.

We should allow for some margin of error in our analysis. As we've said - it is not possible to deterministically get all UK25k data by each department.

It is possible that some data is available on other UK data portals (not data.gov.uk), it is possible that we could not find some data (due to the way we have to use search queries to discover data), it is possible we'veerroneously identified some data (ditto), and so on.

By analysing the errors that persist over this data, one sees patterns that are common fodder for civic tech data wranglers:

- columns with inconsistent data (example: strings in data columns)
- blank rows
- non-tabular data at the beginning and end of files
- inconsistent header naming

#+END_NOTES

** 

- A global leader in open data publication
- A case with a clear edict of requirements
- A simple and explicit "standard" to publish to

** 

- % of valid files rounds to zero
- Issues of file structure and schema
- Issues of timeliness (or, discoverability - take your pick)

** 

- [[http://uk-25k.datadashboards.io][UK 25k Data Quality Dashboard]]
- [[https://github.com/okfn/data-quality-uk-25k-spend][Collected data and processing scripts]]
- [[https://www.gov.uk/government/uploads/system/uploads/attachment_data/file/198197/Guidance_for_publishing_spend_over__25k.pdf][Official guidance from HMT for publishing spend]]

** EU subsidy data

[[./assets/sseu.png]]

#+BEGIN_NOTES

1. How easy is it to build an app using EU fiscal data?
2. Data wrangling (hundreds of ETL pipelines, radically inconsistent data, even in single files).
3. Time and effort - the cost of "open data publication" at this quality.

------

https://okfn.de/blog/2017/04/Making-EU-Data-Open/

In 2016, we undertook a project with Open Knowledge Germany to bring together a large subsection of EU subsidy data, and centralise it into the OpenSpending database for deeper analysis. 

We knew this was not a small job: there are data standards and regulations at the EU for the publication of this data, but there are not consistently adhered to. We set out to identify and source around 140 different datasets, across a range of regional data portals. Like wit the UK example, the data quality issues already start at the discovery stage - it is a significant amount of work just to *identify* where this "open data" can be found. 

In this "data sourcing" stage we experienced the next step of data quality - while the data is supposed to be published in open data formats, much wasn't. In the end we extracted data from formats X, Y, and Z, and from over X different data portals across Europe. 

#+END_NOTES

** 

- Clear publication requirements via an EU regulation
- Centralised entiy (EU) paying out across multiple regions (comparability opportunity)
- Huge investments by EU in open data and related tech (H2020 and similar programs)

** 

- Extremely bad data issues within single files
- No consistency across data actually published, making comparison impossible
- Much data not actually published in machine-readable formats

** 

- [[http://subsidystories.eu][Subsidy Stories EU app]]
- [[https://github.com/os-data/eu-structural-funds/][Data collection and processing code]]
- [[http://openbudgets.eu/assets/resources/Report-OpenBudgets-ESIF%20Data-Quality-Index.pdf][Data quality report]]

** Others
** 

#+BEGIN_QUOTE
When released, data is not always useful and useable.... Only France published the majority of its datasets in line with open data standards. - from [[https://www.transparency.org/news/feature/open_data_promise_but_not_enough_progress_from_g20_countries][Open Data: Promise but not enough progress]] by Transparency International
#+END_QUOTE

** 

#+BEGIN_QUOTE
... cities ... put out more data with lower usability (because metadata isn’t available, or is of poor quality) ... [and] ... undermine cities’ ability to deliver on open data’s transparency-driven mission. - from [[http://datasmart.ash.harvard.edu/news/article/an-open-letter-to-the-open-data-community-988][An Open Letter to the Open Data Community]] by Data Smart City Solutions
#+END_QUOTE

** 

#+BEGIN_QUOTE
... we recommend that ... data quality is increased to the legally mandated minimum throughout Europe. ... governments should introduce centralised control mechanisms and *penalties for non-compliance*. - from [[https://opentender.eu/blog/2017-03-recommendations-for-implementation/#guide7][Towards more transparent and efficient contracting]] by Digiwhist
#+END_QUOTE

#+BEGIN_NOTES

------

https://github.com/datagovuk/spend-prototype#etl-scripts

"...4,606,759 transactions. A few hundred thousand not imported due to failures in formatting. Over 1000 original pages, we ended up with 1,1993 CSV files."

http://blog.nkb.fr/data-free : 

"Sometimes, no data is better than bad data."

"Being able to access bogus data is pointless. What is needed to make sense of the world around us is better data, free from government interference. To be free to contextualize news, free to interpret events and free to think independently, we need independently collected data.

This is important because good information is a prerequisite for the bureaucracy to run properly. Removing good data is like removing the foundations of our administrations. And this is already happening."

#+END_NOTES

* Learnings

#+REVEAL_HTML: <i class="fa fa-graduation-cap" aria-hidden="true"></i>

** 

- Governments leading on open data cannot publish consistent CSV files
- Standards and regulations do not lead to quality, reusable data
- Huge amounts of time and money are required to get to insight

#+BEGIN_NOTES

1. The EU and the UK spend huge amount of money on transparency and on open data, including investment in highly technical solutions like Linked Data.
2. Many voices from both civil society and government argue for standards, but our studies here shown that standards for data publication don't correlate with quality. Different problems.
3. Most painful (for me), this all deeply impacts the ability to generate insight from and with open data. Vast amounts of opportunities are lost, as resources are channeled to much more mundane data processing tasks. This also significantly raises the barrier to entry

#+END_NOTES

* Quality

#+REVEAL_HTML: <i class="fa fa-star" aria-hidden="true"></i>

** What do we want?

#+BEGIN_QUOTE
(W)e want the data raw, and we want the data now - from [[https://blog.okfn.org/2007/11/07/give-us-the-data-raw-and-give-it-to-us-now/][Give Us the Data Raw, and Give it to Us Now]] by Rufus Pollock
#+END_QUOTE

#+BEGIN_NOTES

1. Rufus Pollock, Founder of OKI, famously said in 2007 that we want the raw data and we want the data now.
2. 10 years later, yes, give us the raw data if that is all you have. But, we need to be proactive in demanding more.
3. We can't only incentivise governments for raw publication and access. We need to incentivise data quality, towards actual insight and change.

#+END_NOTES

** Goals

- plain text data
- structural integrity
- schematic consistency
- timely release

#+BEGIN_NOTES

In reaching for quality, we need to understand the essential foundations, and not introduce layers of complexity that delay and even prevent publication.

Note that here the foundations I'm claiming are simpler than those implied by the Open Data Charter, which talks about higher-level concepts such as "linkability" and "comparability". DEFRA in the UK government also publishes some open data principles along the same lines.

I'm concerned that these focus too much on the concepts and technology of Linked Data, and miss out on a more foundational step.

Also, these types of declarations and principles are almost exclusively concerned with the consumption of open data, largely ignoring the production of open data. This has implications related to the technologising of solutions, that I'll talk about shortly.

The bottom line is, without a simple, solid foundation of *structural integrity*, *schematic consistency*, and *timely release*, we will not meet quality standards higher up in the chain.

#+END_NOTES

** Non-goals

- Fixed data standards
- Common code lists
- Automated comparision
- Linkage across datasets

#+BEGIN_NOTES

1. I'm a big fan of all of these things, and actively working on some (data standards). I'm also a big fan of scoping and iterative progress. These are nice things that we can't have yet.
2. Some of this is better done by domain experts or towards specific ends (e.g.: OpenSpending and fiscal data). Generic code list and linking solutions are bound to fall short for a great many use cases.
3. Solutions to these non-goals are inherently technical (part of their appeal to some). Classic case of engineering solving a problem. Just yesterday XKCD published a comiic on this tendency. I think we are seeing the same type of thing with some approaches around Linked Open Data.

------

I am a big fan of all of these things. We should, as an ecosystem, be moving towards these things consistently. However, they should be based only on the previous foundations.

All of these things take us away from basic plain text publication of data, and introduce complexities via increased dependance on *technology* and *domain knowledge*.

We need to have essential quality assurances in plain text publication of data first, for data that is published via manual and automated means.

Why we should work to all of these on top of the previous foundations:

- *Data standards*: Technologists love standards (me too! I work on a few). Data can be published and standardaized without standards (FDP example).

- *Code lists*: Technologists love code lists.
  - Most humans have no idea what we are talking about. (problem of complexity in production.)
  - Almost all data cannot be mapped 1:1 to common code lists. (problem of compelxity related to regulation, law, and so on.)

- *Comparison*: Comparison is extremely hard across even very similar datasets. (example: of muni fiscal data and changes across entities - different usage of same code - and over time,)

- *Linkage*: Things not strings is a common phrase used by Linked Data proponents. We are all working towards this, but it is again incredibly domain specific. Similar end goals can be achieved through simpler quality mechanisms.

Lastly, a lot of this comes out of context: data published tp the basic quality foundations above allows domain experts to do these things in more specific and granular ways, for their goals.

#+END_NOTES

*** xkcd.com/1831/

[[./assets/xkcd.com_1831.png]]

* Action

#+REVEAL_HTML: <i class="fa fa-universal-access" aria-hidden="true"></i>

** 

What can we do to get governments to publish quality open data?

#+BEGIN_NOTES

1. I'm not here solely to complain about the current situation of open data!
2. Governments need us, the consumers of their open data, to be vocal and guiding in increasting the quality of open data.
3. This is not a problem space with a purely technological solution.

------

What actions can we, open data activists, hackers, and so on, take now to get governments to publish quality open data?

I don't believe in technical solutions to issues that are socio-political in nature.

Governments, or more specifically the transparency and open data arms within them, think they are on the right track with data publication and it is up to us, the consumers of that data, to make them painfully aware of the shortcomings of what is currently being published.

We can't do this only by coding software. We can develop some solutions in software, that need to be leveraged by civic tech (etc.) to show their governments (at all levels) and serve as the basis for a discussion of change - a change to value data quality as part of the data publication process.

#+END_NOTES

** Non-tech

#+REVEAL_HTML: <i class="fa fa-users" aria-hidden="true"></i>

*** 

- Engage in direct dialogue with government on the usability of open data
- Build quality metrics into the processes that incentivise government
- In some situations, outright reject data as open data based on quality grounds alone

#+BEGIN_NOTES

1. Data wrangling effort, high level of entry for insight.
2. From NGO initiatives like the Open Data Index, through to government partnerships like the OGP.
3. As a step in bringing quality into mainstream discourse on open data, identify certain types of open data that MUST meet certain quality standards. Fiscal data could be one.

#+END_NOTES

** Tech

#+REVEAL_HTML: <i class="fa fa-cubes" aria-hidden="true"></i>

*** Data validation

- Structural and schematic checks
- Reports actionable by non-technical users
- [[https://github.com/frictionlessdata/goodtables-py][goodtables]] and [[https://github.com/frictionlessdata/data-quality-spec][Data Quality Spec]]

*** Quality dashboards

- Log data quality over collections of data
- Track change over time
- Target actors in policy and implementation
- [[https://github.com/frictionlessdata/data-quality-dashboard][Data Quality Dashboard]]

*** Future portals

- More emphasis on publication workflows
- More emphasise on internal visibility into "data health"
- Automation/controls around publishing based on health checks

#+BEGIN_NOTES

1. *More emphasis on the means of production*.
2. This is not a complete list - only things in reference to data quality.

#+END_NOTES

* Thanks

#+REVEAL_HTML: <i class="fa fa-hourglass-end" aria-hidden="true"></i>
